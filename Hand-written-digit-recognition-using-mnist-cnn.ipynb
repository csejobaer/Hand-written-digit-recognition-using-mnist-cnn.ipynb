from numpy import unique, argmax
from tensorflow.keras.datasets.mnist import load_data
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dropout
from tensorflow.keras.utils import plot_model
from matplotlib import pyplot
import matplotlib.pyplot as plt
import numpy as np
print("import ok")


#loading the MNIST dataset
(xTrain, yTrain), (xTest, yTest) = load_data()
#reshaping the traninig and testing data. reshape dataset to have a single channel
xTrain = xTrain.reshape((xTrain.shape[0], xTrain.shape[1], xTrain.shape[2], 1))
xTest = xTest.reshape((xTest.shape[0], xTest.shape[1], xTest.shape[2], 1))
print("Dataset load and reshape completed")


#Normalize the dateses(convert to  0-255 to unsigned to 0-1 of pixel value) improve the performance of the model
xTrain = xTrain.astype('float32')/255.0
xTest = xTest.astype('float32')/255.0
print("Dataset has been normalized")


fig = plt.figure(figsize=(5, 3)) #image isze
print("Displayed set of 20 images")
for i in range(20): #first 20 setup image
  ax = fig.add_subplot(2, 10, i+1, xticks=[], yticks=[]) # set given sub plot also set title of y train
  ax.imshow(np.squeeze(xTrain[i]), cmap='gray')
  ax.set_title(yTrain[i])


#Now check single image shape
print("Single input image shape")
image_shape = xTrain.shape[1:]
print(image_shape)


#define model
#first sequential model
model = Sequential()
#second Covolutional layer/ max pooling  layer
#model.add(Conv2D(32, (3, 3), activation='relu', input_shape=inp_shape)) 
#In this perticular layer has 32 filter
#Here 3x3 is the size of the filter
#We use relu as activation function
#Then the last parameter use the size of the input
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
# Two convolution layer around the max pooling layer
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(48, (3, 3), activation='relu'))
# Two convolution layer around the max pooling layer
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.5))
model.add(Flatten())
#500 nodes which are there in the network layer
model.add(Dense(500, activation='relu'))
#10 nodes which are there in the output layer 
model.add(Dense(10, activation='softmax'))





model.summary() #Check the model summary

# New see the model how actually look
plot_model(model, 'model.jpg', show_shapes=True)


#We use adam as optimizer(defferent optimizer: nadam, adamax, adagrade, rmsprop) 
#Adam reduce the loss and increase the accuracy
#We use categorical entropy because we have defferent 10 categories of data.
#if we have only two cat theuse binary cross entropy
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])
x = model.fit(xTrain, yTrain, epochs=10, batch_size=128, verbose=2, validation_split=0.1)


image = xTrain[1]
#Now display the image that we what to predict
plt.imshow(np.squeeze(image), cmap='gray')
plt.show()


image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])
#Now check the predicted label correct or not
result = model.predict([image])
print("predicted result: ", argmax(result))


#Now check the accuracy of the model
loss, accuracy = model.evaluate(xTest, yTest, verbose = 0)
print("Accuracy: ", accuracy*100)
